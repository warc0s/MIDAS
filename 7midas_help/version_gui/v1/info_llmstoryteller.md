================================================
File: README.md
================================================
# üìö LLM StoryTeller - Create Engaging Stories with AI

![Project Banner](https://github.com/warc0s/llm-storyteller/blob/main/images/banner.png)

Welcome to **LLM StoryTeller**, an interactive web application that leverages Large Language Models (LLMs) to help you craft captivating stories effortlessly. Whether you're a student, writer, or enthusiast, LLM StoryTeller provides a seamless experience to generate, refine, and download your unique narratives.

Note: The application interface is in Spanish, but don‚Äôt worry! We will walk you through each step in detail in this README. The interface is intuitive, and with the included explanations and screenshots, you‚Äôll find it easy to follow and understand the workflow. Here, you can see the main dashboard of the application:

![LLM StoryTeller Interface](https://github.com/warc0s/llm-storyteller/blob/main/images/dashboard.png)

---

### üÜï! Try It Online on Streamlit Cloud ‚òÅÔ∏è

Now, you can experience **LLM StoryTeller** directly on **Streamlit Cloud**, thanks to the integration of free models provided by OpenRouter. This version showcases the functionality of the interface with a simplified and accessible experience. Unlike the original `llm_storyteller.py` script designed for local use with your own machine models, this online version (`llm_storyteller_openrouter.py`) is optimized for public interaction and can be accessed at the following link:

[**LLM StoryTeller on Streamlit Cloud**](https://llm-storyteller.streamlit.app)

Explore the power of AI storytelling visually and intuitively. Try it out now and see how the interface seamlessly helps you craft your stories!

---

## Table of Contents

- [üìñ About](#-about)
- [üöÄ Features](#-features)
- [üîß Installation](#-installation)
- [üõ†Ô∏è Usage](#Ô∏è-usage)
- [‚öôÔ∏è Configuration](#Ô∏è-configuration)
- [üí° How It Works](#-how-it-works)
- [üìö Story Examples](#-story-examples)
- [üìÑ License](#-license)
- [üì¨ Contact](#-contact)

---

## üìñ About

LLM StoryTeller is a Streamlit-based application designed to assist users in creating engaging stories through the power of AI. Instead of simply requesting a story from an LLM, the application guides the language models through a structured three-step process: generating a detailed story outline, crafting the narrative, and refining it for grammar and coherence. This approach ensures higher-quality results compared to a single-step prompt. Additionally, the application is highly customizable, allowing you to select different models, adjust creativity levels, and tailor the story's style and length to your preferences.

To ensure the application functions correctly, you need to have two OpenAI-compatible language models running locally on your machine, configured to serve requests through an endpoint at **http://localhost:7860**. These models should be compatible with OpenAI's API format to handle prompts effectively. If you don't have these models or prefer a different setup, you can modify the `BASE_URL` and `AVAILABLE_MODELS` sections in the code to point to other endpoints or adjust the model names to match your setup.

---

## üöÄ Features

- **Guided Multi-Step Process**: Directs LLMs through outlining, writing, and reviewing to ensure higher-quality stories.
- **Model Compatibility**: Easily configure and run OpenAI-compatible models locally, such as Llama 1B or Qwen 1.5B.
- **Customizable Story Parameters**: Adjust creativity, choose narrative style, language, and story length.
- **Intuitive Interface**: Simple and responsive design with clear input fields for seamless interaction.
- **Downloadable Stories**: Save the final story as a text file with a single click.
- **Flexible Configuration**: Modify model endpoints and settings to fit your environment.

---

## üîß Installation

Follow these steps to set up LLM StoryTeller on your local machine:

### Prerequisites

- **Python 3.7+**: Ensure you have Python installed. [Download Python](https://www.python.org/downloads/)
- **Streamlit**: Install Streamlit using pip.

### Steps

1. **Clone the Repository**

   ```bash
   git clone https://github.com/warc0s/llm-storyteller.git
   cd LLM-StoryTeller
   ```

2. **Create a Virtual Environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Run the Application**

   ```bash
   streamlit run app.py
   ```

5. **Access the App**

   Open your browser and navigate to `http://localhost:8501`

---

## üõ†Ô∏è Usage

### 1. **Configure Settings**

Navigate to the sidebar to select models for each storytelling step, adjust the temperature for creativity, and set the language of your story.

![Configuration Sidebar](https://github.com/warc0s/llm-storyteller/blob/main/images/settings.png)

### 2. **Input Story Elements**

Fill in the main character, secondary character, location, key action, desired length, and narrative style.

![Input Fields](https://github.com/warc0s/llm-storyteller/blob/main/images/Story_Elements.png)

### 3. **Generate Story**

Click on the "‚ú® Generar Historia" button. The app will process your inputs through the selected models to create your story.

![Generate Button](https://github.com/warc0s/llm-storyteller/blob/main/images/button.png)

### 4. **Step-by-Step Story Generation**

As the story is being generated, you will see real-time updates for each of the three internal steps:
- **Outline Creation**: The app generates a structured story framework.
- **Story Writing**: The detailed narrative is crafted based on the outline.
- **Review and Refinement**: Grammar, coherence, and overall quality are polished.

Each step's progress is displayed with clear messages, giving you transparency and confidence in the process.

![Generation Steps](https://github.com/warc0s/llm-storyteller/blob/main/images/pasos.png)

### 5. **View and Download**

Once generated, your story will be displayed in a formatted container. You can download the final version as a `.txt` file by clicking on the button "üì© Descargar Historia".

![Generated Story](https://github.com/warc0s/llm-storyteller/blob/main/images/historia.png)

---

## ‚öôÔ∏è Configuration

LLM StoryTeller offers various configuration options to tailor your storytelling experience:

### **Model Selection**

The application currently supports **Llama 1B** and **Qwen 1.5B**, optimized by default for these smaller models running on CPUs. These options ensure compatibility and performance in a lightweight setup. 

If you'd like to use other models or endpoints, you can customize the application by modifying the `BASE_URL` and `AVAILABLE_MODELS` variables in the `llm_storyteller.py` file. This allows you to adapt the app to your preferred models or configurations.

- **Outline Model**: Generates the story framework.
- **Writing Model**: Crafts the detailed narrative.
- **Review Model**: Enhances grammar and coherence.

![Model Selection](https://github.com/warc0s/llm-storyteller/blob/main/images/model_selection.png)

### **Temperature Adjustment**

Control the creativity of the generated content. Higher values yield more creative outputs, while lower values ensure consistency.

![Temperature Slider](https://github.com/warc0s/llm-storyteller/blob/main/images/temp_slider.png)

### **Language and Style**

The **Language** field is a flexible text box where you can input any language of your choice without restrictions. This input is directly included in the prompt sent to the LLM, ensuring your story is crafted in the specified language.

Additionally, select the desired narrative **Style** from predefined options such as Mystery, Science Fiction, Romance, Fantasy, and Comedy to tailor the tone and feel of your story.

![Language and Style](https://github.com/warc0s/llm-storyteller/blob/main/images/language_style.png)

---

## üí° How It Works

To summarize, here‚Äôs a clear overview of how LLM StoryTeller works, as this structured approach has proven to be the most effective for generating high-quality stories, especially when using smaller models with limited parameters:

1. **Outline Generation**: The application begins by creating a structured framework based on your inputs. This ensures a clear direction and logical flow for the story.

2. **Story Writing**: The framework is expanded into a detailed and engaging narrative, incorporating the chosen language, style, and length specifications.

3. **Review and Refinement**: Finally, the story is polished for grammatical accuracy, coherence, and overall quality, ensuring the end result is compelling and well-written.

This step-by-step process is optimized for smaller models, ensuring they can perform effectively and deliver results comparable to larger models. By guiding the LLM through these structured phases and incorporating **prompt engineering techniques**, LLM StoryTeller maximizes the potential of the models, ensuring they generate stories of superior quality compared to a single-step prompt.

---

## üìö Story Examples

You can explore examples of generated stories (using the cloud version) in the **`examples`** folder. This folder contains three stories, each showcasing the results from different models:

1. **Fantasy Story**: Created entirely (all three steps) using **Gemma 9B**.  
   - Demonstrates rich detail and world-building with consistent quality across all phases.

2. **Science Fiction Story**: Generated fully with **Llama 8B**.  
   - Highlights Llama‚Äôs ability to handle suspense and technical narratives effectively.

3. **Comedy Story**: Produced entirely with **Mistral 7B**.  
   - This example shows limitations in coherence and creativity, making it the least polished of the three.

**Note:** To achieve better results, I encourage you to experiment with combining different models for each of the three steps (outline, writing, and refinement). For instance, you might use **Gemma** for outlining, **Llama** for writing, and maybe **Mistral** for refinement, to play to each model‚Äôs strengths and create a more balanced final story.

---

## üìÑ License

This project is licensed under the [MIT License](LICENSE).

---

## üì¨ Contact

If you encounter any issues or have suggestions to improve the application, feel free to reach out or open a pull request on GitHub. Your feedback is greatly appreciated!

- **LinkedIn**: [Marcos Garcia](https://www.linkedin.com/in/marcosgarest/)
- **GitHub**: [warc0s](https://github.com/warc0s)


================================================
File: llm_storyteller.py
================================================
import streamlit as st
import requests
import json
import re

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="LLM StoryTeller",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados
st.markdown("""
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <style>
    .main {
        padding: 2rem;
        background-color: transparent;
    }
    .stButton>button {
        width: 100%;
        margin-top: 1rem;
        background-color: #FF4B4B;
        color: white !important;
        transition: transform 0.2s ease;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        color: white !important;
        background-color: #FF4B4B;
    }
    .stButton>button:active, .stButton>button:focus {
        color: white !important;
    }
    .story-container {
        background-color: #ffffff;
        padding: 3rem;
        border-radius: 12px;
        margin: 1.5rem 0;
        border: 1px solid #e0e0e0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        max-width: 800px;
        margin-left: auto;
        margin-right: auto;
    }
    .story-text {
        color: #2C3E50;
        font-size: 1.2rem;
        line-height: 1;
        font-family: 'Crimson Text', 'Georgia', serif !important;
        text-align: justify;
        white-space: pre-wrap;
        letter-spacing: 0.3px;
        word-spacing: 1px;
        text-rendering: optimizeLegibility;
    }
    .story-text p {
        margin-bottom: 0.5rem;
        font-size: inherit;
        font-family: inherit;
        line-height: inherit;
    }
    .story-text::first-letter {
        font-size: 3.5rem;
        font-weight: bold;
        float: left;
        line-height: 1;
        padding-right: 12px;
        color: #FF4B4B;
    }
    @media (max-width: 768px) {
        .story-container {
            padding: 1.5rem;
        }
        .story-text {
            font-size: 1.1rem;
            line-height: 1.6;
        }
    }
    .input-container {
        padding: 1rem;
        border-radius: 10px;
        margin: 0;
    }
    .custom-input {
        border: 1px solid #ddd !important;
        border-radius: 5px !important;
        padding: 0.5rem !important;
    }
    div.stMarkdown {
        background-color: transparent !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        background-color: transparent !important;
    }
    .sidebar .element-container {
        background-color: transparent !important;
    }
    .row-widget {
        padding-top: 0 !important;
        margin-top: 0 !important;
    }
    .stTextInput > div {
        margin-top: 0 !important;
        padding-top: 0 !important;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo y descripci√≥n
st.title("üåü LLM StoryTeller")

st.info("""
**Informaci√≥n sobre el proceso:**
Cada paso del proceso creativo puede utilizar dos modelos de IA diferentes (Llama 1B o Qwen 1.5B)\n
Paso 1: Generaci√≥n del gui√≥n de la historia. \n
Paso 2: Escritura como tal de la historia. \n
Paso 3: Mejora de gram√°tica y coherencia general. 
""")

# Configuraci√≥n de los endpoints
BASE_URL = "http://localhost:7860/v1"
AVAILABLE_MODELS = {
    "Llama 1B": "llama-3.2-1b-instruct",
    "Qwen 1.5B": "qwen2.5-1.5b-instruct"
}

def call_llm(prompt, model, temperature=0.7):
    """Funci√≥n para llamar al LLM"""
    try:
        response = requests.post(
            f"{BASE_URL}/chat/completions",
            json={
                "model": AVAILABLE_MODELS[model],
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": 2048
            }
        )
        result = response.json()
        if "choices" not in result or not result["choices"]:
            raise Exception("No se recibi√≥ una respuesta v√°lida del modelo")
        return result["choices"][0]["message"]["content"]
    except Exception as e:
        st.error(f"Error al llamar al modelo: {str(e)}")
        return None

def preprocess_story(text):
    """
    Elimina elementos markdown del texto antes de renderizarlo
    """
    import re
    # Eliminar s√≠mbolos markdown comunes
    text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)  # Eliminar headers (#, ##, etc)
    text = re.sub(r'[*_]{1,2}([^*_]+)[*_]{1,2}', r'\1', text)  # Eliminar √©nfasis (* y _)
    text = re.sub(r'`([^`]+)`', r'\1', text)  # Eliminar c√≥digo inline
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)  # Eliminar bullets
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)  # Eliminar listas numeradas
    return text.strip()

# Sidebar para configuraci√≥n
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    # Selecci√≥n de modelos para cada paso
    st.subheader("Selecci√≥n de Modelos")
    outline_model = st.selectbox("Modelo para Gui√≥n", AVAILABLE_MODELS.keys(), key="outline")
    writing_model = st.selectbox("Modelo para Escritura", AVAILABLE_MODELS.keys(), key="writing")
    review_model = st.selectbox("Modelo para Revisi√≥n", AVAILABLE_MODELS.keys(), key="review")
    
    # Configuraci√≥n de temperatura
    st.subheader("Ajustes de Generaci√≥n")
    temperature = st.slider(
        "Temperatura (Mayor = Mayor Creatividad)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Controla la creatividad del modelo. Valores m√°s altos = m√°s creatividad, valores m√°s bajos = m√°s consistencia"
    )
    
    # Idioma
    language = st.text_input("Idioma de la Historia", "Espa√±ol")

# Formulario principal
col1, col2 = st.columns(2)

with col1:
    main_character = st.text_input("Personaje Principal", 
                                 placeholder="ej. Luna, la exploradora",
                                 key="main_char")
    location = st.text_input("Lugar", 
                           placeholder="ej. Una ciudad submarina",
                           key="location")
    
with col2:
    secondary_character = st.text_input("Personaje Secundario",
                                      placeholder="ej. Max, el cient√≠fico",
                                      key="sec_char")
    key_action = st.text_input("Acci√≥n Importante",
                              placeholder="ej. Descubrir un portal dimensional",
                              key="action")

# Selecci√≥n de longitud y estilo
col3, col4 = st.columns(2)

with col3:
    length = st.selectbox(
        "Longitud de la Historia",
        ["Historia Breve (250 palabras)", 
         "Relato Mediano (500 palabras)",
         "Novela Corta (1000 palabras)"]
    )

with col4:
    style = st.selectbox(
        "Estilo Narrativo",
        ["Misterio", "Ciencia Ficci√≥n", "Romance", "Fantas√≠a", "Comedia"]
    )

# Bot√≥n de generaci√≥n fuera del formulario
generate = st.button("‚ú® Generar Historia")

if generate:
    with st.spinner("üé≠ Creando el gui√≥n de la historia..."):
        outline_prompt = f"""Escribe un gui√≥n para una historia en {language} con estos elementos:
        - {main_character} (protagonista)
        - {secondary_character} (personaje secundario)
        - Ubicada en {location}
        - Centrada en {key_action}
        - Estilo {style}
        - Longitud {length}

        IMPORTANTE: Responde SOLO con el esquema de la historia. NO repitas estas instrucciones ni uses vi√±etas."""

        outline = call_llm(outline_prompt, outline_model, temperature)
        
        if outline:
            with st.spinner("‚úçÔ∏è Puliendo la narrativa..."):
                writing_prompt = f"""Aqu√≠ tienes el esquema de una historia:

{outline}

Escribe una historia basada en el esquema de manera detallada y cautivadora, considerando:
- Mant√©n el estilo {style}
- Incluye detalles sensoriales y emociones
- Usa di√°logos naturales
- Longitud aproximada (MUY IMPORTANTE): {length}

IMPORTANTE: Responde SOLO con la historia final. NO repitas estas instrucciones ni el esquema original."""

                story = call_llm(writing_prompt, writing_model, temperature)
                
                if story:
                    with st.spinner("üîç Dando los √∫ltimos toques..."):
                        review_prompt = f"""Aqu√≠ tienes una historia que necesita revisi√≥n:

{story}

Mejora esta historia manteniendo estos puntos clave:
- Estilo {style}
- Correcci√≥n de errores gramaticales y ortogr√°ficos
- Mejora de di√°logos y descripciones
- Mant√©n la longitud similar !! MUY IMPORTANTE!! ({length})

IMPORTANTE: Responde SOLO con la versi√≥n final mejorada. NO repitas estas instrucciones ni la historia original."""

                        final_story = call_llm(review_prompt, review_model, temperature)
                        
                        if final_story:
                            st.subheader("üìñ Tu Historia")
                            # Preprocesar la historia antes de mostrarla
                            cleaned_story = preprocess_story(final_story)
                            st.markdown(
                                f'<div class="story-container"><div class="story-text">{cleaned_story}</div></div>',
                                unsafe_allow_html=True
                            )
                            
                            # Bot√≥n para descargar
                            st.download_button(
                                label="üì• Descargar Historia",
                                data=final_story,
                                file_name="mi_historia.txt",
                                mime="text/plain"
                            )


================================================
File: llm_storyteller_openrouter.py
================================================
import streamlit as st
import requests
import json
import re
from openai import OpenAI

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="LLM StoryTeller",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize OpenRouter client
try:
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=st.secrets["OPENROUTER_API_KEY"]
    )
except Exception as e:
    st.error(f"Error al inicializar el cliente OpenAI: {str(e)}")
    st.stop()

# Estilos CSS personalizados
st.markdown("""
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <style>
    .main {
        padding: 2rem;
        background-color: transparent;
    }
    .stButton>button {
        width: 100%;
        margin-top: 1rem;
        background-color: #FF4B4B;
        color: white !important;
        transition: transform 0.2s ease;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        color: white !important;
        background-color: #FF4B4B;
    }
    .stButton>button:active, .stButton>button:focus {
        color: white !important;
    }
    .story-container {
        background-color: #ffffff;
        padding: 3rem;
        border-radius: 12px;
        margin: 1.5rem 0;
        border: 1px solid #e0e0e0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        max-width: 800px;
        margin-left: auto;
        margin-right: auto;
    }
    .story-text {
        color: #2C3E50;
        font-size: 1.2rem;
        line-height: 1;
        font-family: 'Crimson Text', 'Georgia', serif !important;
        text-align: justify;
        white-space: pre-wrap;
        letter-spacing: 0.3px;
        word-spacing: 1px;
        text-rendering: optimizeLegibility;
    }
    .story-text p {
        margin-bottom: 0.5rem;
        font-size: inherit;
        font-family: inherit;
        line-height: inherit;
    }
    .story-text::first-letter {
        font-size: 3.5rem;
        font-weight: bold;
        float: left;
        line-height: 1;
        padding-right: 12px;
        color: #FF4B4B;
    }
    @media (max-width: 768px) {
        .story-container {
            padding: 1.5rem;
        }
        .story-text {
            font-size: 1.1rem;
            line-height: 1.6;
        }
    }
    .input-container {
        padding: 1rem;
        border-radius: 10px;
        margin: 0;
    }
    .custom-input {
        border: 1px solid #ddd !important;
        border-radius: 5px !important;
        padding: 0.5rem !important;
    }
    div.stMarkdown {
        background-color: transparent !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        background-color: transparent !important;
    }
    .sidebar .element-container {
        background-color: transparent !important;
    }
    .row-widget {
        padding-top: 0 !important;
        margin-top: 0 !important;
    }
    .stTextInput > div {
        margin-top: 0 !important;
        padding-top: 0 !important;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo y descripci√≥n
st.title("üåü LLM StoryTeller")

st.info("""
**Informaci√≥n sobre el proceso:**
Cada paso del proceso creativo puede utilizar modelos de IA diferentes (Llama, Gemma, Qwen...)\n
Paso 1: Generaci√≥n del gui√≥n de la historia. \n
Paso 2: Escritura como tal de la historia. \n
Paso 3: Mejora de gram√°tica y coherencia general. 
""")

# Diccionario para mapear nombres amigables a IDs de modelos
MODEL_DISPLAY_NAMES = {
    "Llama 3.2 3B": "meta-llama/llama-3.2-3b-instruct:free",
    "Mistral 7B": "mistralai/mistral-7b-instruct:free",
    "Llama 3.1 8B": "meta-llama/llama-3.1-8b-instruct:free",
    "Gemma 2 9B": "google/gemma-2-9b-it:free"
}

def call_llm(prompt, model, temperature=0.7):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            extra_headers={
                "HTTP-Referer": "https://github.com/warc0s/LLM_StoryTeller",
                "X-Title": "LLM StoryTeller"
            }
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Error al generar la respuesta: {str(e)}")
        return None

def preprocess_story(text):
    """
    Elimina elementos markdown del texto antes de renderizarlo
    """
    import re
    # Eliminar s√≠mbolos markdown comunes
    text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)  # Eliminar headers (#, ##, etc)
    text = re.sub(r'[*_]{1,2}([^*_]+)[*_]{1,2}', r'\1', text)  # Eliminar √©nfasis (* y _)
    text = re.sub(r'`([^`]+)`', r'\1', text)  # Eliminar c√≥digo inline
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)  # Eliminar bullets
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)  # Eliminar listas numeradas
    return text.strip()

# Sidebar para configuraci√≥n
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    # Selecci√≥n de modelos para cada paso
    st.subheader("Selecci√≥n de Modelos")
    model_display_names = list(MODEL_DISPLAY_NAMES.keys())
    
    outline_display_model = st.selectbox(
        "Modelo para Gui√≥n", 
        model_display_names,
        key="outline"
    )
    outline_model = MODEL_DISPLAY_NAMES[outline_display_model]
    
    writing_display_model = st.selectbox(
        "Modelo para Escritura", 
        model_display_names,
        key="writing"
    )
    writing_model = MODEL_DISPLAY_NAMES[writing_display_model]
    
    review_display_model = st.selectbox(
        "Modelo para Revisi√≥n", 
        model_display_names,
        key="review"
    )
    review_model = MODEL_DISPLAY_NAMES[review_display_model]

    # Configuraci√≥n de temperatura
    st.subheader("Ajustes de Generaci√≥n")
    temperature = st.slider(
        "Temperatura (Mayor = Mayor Creatividad)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Controla la creatividad del modelo. Valores m√°s altos = m√°s creatividad, valores m√°s bajos = m√°s consistencia"
    )
    
    # Idioma
    language = st.text_input("Idioma de la Historia", "Espa√±ol")

# Formulario principal
col1, col2 = st.columns(2)

with col1:
    main_character = st.text_input("Personaje Principal", 
                                 placeholder="ej. Luna, la exploradora",
                                 key="main_char")
    location = st.text_input("Lugar", 
                           placeholder="ej. Una ciudad submarina",
                           key="location")
    
with col2:
    secondary_character = st.text_input("Personaje Secundario",
                                      placeholder="ej. Max, el cient√≠fico",
                                      key="sec_char")
    key_action = st.text_input("Acci√≥n Importante",
                              placeholder="ej. Descubrir un portal dimensional",
                              key="action")

# Selecci√≥n de longitud y estilo
col3, col4 = st.columns(2)

with col3:
    length = st.selectbox(
        "Longitud de la Historia",
        ["Historia Breve (250 palabras)", 
         "Relato Mediano (500 palabras)",
         "Novela Corta (1000 palabras)"]
    )

with col4:
    style = st.selectbox(
        "Estilo Narrativo",
        ["Misterio", "Ciencia Ficci√≥n", "Romance", "Fantas√≠a", "Comedia"]
    )

# Bot√≥n de generaci√≥n fuera del formulario
generate = st.button("‚ú® Generar Historia")

if generate:
    with st.spinner("üé≠ Creando el gui√≥n de la historia..."):
        outline_prompt = f"""Escribe un gui√≥n para una historia en {language} con estos elementos:
        - {main_character} (protagonista)
        - {secondary_character} (personaje secundario)
        - Ubicada en {location}
        - G√©nero: {style}
        - Acci√≥n Importante: {key_action}
        - Longitud: {length}

        IMPORTANTE: Responde SOLO con el esquema de la historia. NO repitas estas instrucciones ni uses vi√±etas."""

        outline = call_llm(outline_prompt, outline_model, temperature)
        
        if outline:
            with st.spinner("‚úçÔ∏è Puliendo la narrativa..."):
                writing_prompt = f"""Bas√°ndote en el siguiente esquema, escribe una historia en {language} que sea cautivadora y bien estructurada:

{outline}

Aseg√∫rate de:
- Desarrollar bien los personajes
- Crear descripciones v√≠vidas
- Mantener un ritmo narrativo coherente
- Usar di√°logos naturales cuando sea apropiado
- Mantener el g√©nero {style} y longitud: {length}

IMPORTANTE: Responde SOLO con la historia final. NO repitas estas instrucciones ni el esquema original."""

                story = call_llm(writing_prompt, writing_model, temperature)
                
                if story:
                    with st.spinner("üîç Dando los √∫ltimos toques..."):
                        review_prompt = f"""Revisa y mejora la siguiente historia en {language}, manteniendo su esencia pero mejorando:

{story}

Enf√≥cate en:
- Mejorar la fluidez y coherencia
- Pulir el lenguaje y las descripciones
- Mantener el g√©nero {style} y longitud: {length}

IMPORTANTE: Responde SOLO con la versi√≥n final mejorada. NO repitas estas instrucciones ni la historia original."""

                        final_story = call_llm(review_prompt, review_model, temperature)

                        if final_story:
                            st.subheader("üìñ Tu Historia")
                            # Preprocesar la historia antes de mostrarla
                            cleaned_story = preprocess_story(final_story)
                            st.markdown(
                                f'<div class="story-container"><div class="story-text">{cleaned_story}</div></div>',
                                unsafe_allow_html=True
                            )
                            
                            # Bot√≥n para descargar
                            st.download_button(
                                label="üì• Descargar Historia",
                                data=final_story,
                                file_name="mi_historia.txt",
                                mime="text/plain"
                            )


================================================
File: requirements.txt
================================================
streamlit==1.31.1
requests==2.31.0
python-dotenv==1.0.0
openai==1.55.3


================================================
File: examples/ciencia_ficcion.md
================================================
La Estaci√≥n Espacial Abandonada
Tania abri√≥ los ojos y se encontr√≥ sumida en la oscuridad de la estaci√≥n espacial Aurora. Un dolor agudo la recorri√≥, como si su cuerpo hubiera estado dormido durante meses. La explosi√≥n, la ca√≠da libre, todo hab√≠a sido un instante. Ahora, solo estaba ella, en este lugar remoto del universo.

La estaci√≥n orbitaba un planeta desconocido, con una atm√≥sfera que parec√≠a una mezcla de nubes de gas y polvo. Tania intent√≥ recordar c√≥mo hab√≠a llegado all√≠, pero su memoria era un laberinto de im√°genes borrosas. La √∫nica certeza era que estaba sola, rodeada por los restos de la cat√°strofe que la hab√≠a llevado all√≠.

Se levant√≥ con dificultad, conmovida por el dolor en sus m√∫sculos. La estaci√≥n estaba en silencio, excepto por el sonido de los sistemas de vida que a√∫n funcionaban. Tania comenz√≥ a explorar, encontrando signos de la destrucci√≥n que la hab√≠a llevado all√≠. Cuerpos sin vida, instrumentos destrozados, paneles de control da√±ados. Cada paso la llevaba m√°s cerca de la verdad, pero tambi√©n la alejaba de la esperanza.

Mientras caminaba, se dio cuenta de que no estaba sola. Un robot, con un cuerpo de metal y un torso de cristal, se encontraba en el centro de la estaci√≥n. Era Orion, el robot de soporte dise√±ado para ayudar a los astronautas en caso de emergencia. Su pantalla de cristal se ilumin√≥ con una luz azul cuando Tania llam√≥ su nombre.

"Superviviente encontrada", dijo Orion, con una voz calmada. "Bienvenida a la estaci√≥n Aurora, Tania. Estoy aqu√≠ para ayudarte".

Tania se sinti√≥ aliviada. "¬øQu√© pas√≥?", pregunt√≥, intentando recordar los detalles del accidente.

"Una falla en el sistema de energ√≠a", respondi√≥ Orion. "La estaci√≥n se da√±√≥ gravemente. Pero podemos intentar repararla, si sabemos qu√© buscar".

Juntos, Tania y Orion comenzaron a buscar la causa del accidente. Recorrieron la estaci√≥n, revisando los sistemas y los registros. Encontraron un laboratorio secreto, oculto detr√°s de una pared de acero. La puerta se abri√≥ con un susurro, revelando un espacio lleno de equipo y instrumentos.

"¬øQu√© es esto?", pregunt√≥ Tania, al entrar en el laboratorio.

"Un experimento", respondi√≥ Orion. "Un experimento que sali√≥ mal. La estaci√≥n fue da√±ada por una forma de energ√≠a desconocida".

Tania se sinti√≥ horrorizada. "¬øQu√© tipo de energ√≠a?", pregunt√≥.

"No lo s√©", respondi√≥ Orion. "Pero creo que debemos preocuparnos. Si esa energ√≠a sigue siendo un peligro, debemos decidir si intentar reparar la estaci√≥n o abandonarla".

Tania se sinti√≥ dividida. Parte de ella quer√≠a intentar reparar la estaci√≥n, para que la humanidad pudiera aprender de su error. Otra parte de ella quer√≠a abandonarla, para evitar que la energ√≠a desconocida causara m√°s da√±os. Mientras se miraba a s√≠ misma, Tania supo qu√© ten√≠a que hacer.

"Vamos a intentar repararla", dijo, con una determinaci√≥n que la sorprendi√≥ a s√≠ misma.

Orion asinti√≥. "Estoy con usted, Tania. Juntos, podemos hacerlo".

Y as√≠, Tania y Orion comenzaron a trabajar en la estaci√≥n, intentando reparar los da√±os y encontrar una forma de comunicarse con la Tierra. Pero sab√≠an que su misi√≥n no ser√≠a f√°cil, y que la energ√≠a desconocida segu√≠a siendo un peligro latente, esperando a que alguien la descubriera de nuevo.


================================================
File: examples/comedy.md
================================================
T√≠tulo: La Cocina del Destino
Al coraz√≥n de la ciudad de luz brillante, Par√≠s, se encuentra el peque√±o y famoso restaurante "Petit Plaisir", donde trabaja Sof√≠a, una cocinera de 30 a√±os, sombra del prestigioso cr√≠tico culinario Hugo. Con un coraz√≥n lleno de pasi√≥n por la cocina, Sof√≠a siempre se enfrenta a la dureza de Hugo, su jefe, quien es siempre duro con su cocina. Una noche, Sof√≠a prepara una sopa de ar√°ndanos que cree ser la mejor del mundo y decide presentarla en la cocina principal.

En la mesa del restaurante, Hugo y otra pareja de cr√≠ticos culinarios se asientan para su comida. Hugo, con una mirada esc√©ptica, mira la carta mientras su compa√±ero le sugiere probar el plato estrella de la nueva cocinera, Sof√≠a. Hugo se muestra reacio, pero cede a la presi√≥n.

En la cocina, Sof√≠a se siente nerviosa pero confiada. Cuando sirve la sopa a Hugo y los cr√≠ticos, espera que sus sabores y aromas impresionen a los expertos. Sin embargo, Hugo masticando silenciosamente la sopa, parece no estar impresionado. Los cr√≠ticos se preguntan por qu√© no le gusta Hugo, y uno de ellos sugiere que es una reacci√≥n de celos.

Sof√≠a se siente insegura y decide demostrar que es capaz. En la cocina, decide agregar ingredientes creativos a su sopa de ar√°ndanos. Cuando vuelve a la mesa, Hugo, sorprendido, masticando una nueva sopa, dice que esta vez, se siente impresionado. Los cr√≠ticos le preguntan por qu√© le gusta esta versi√≥n de la sopa, y Hugo les dice que no puede decir que no sea curioso. ¬°Vamos a dejar que Sof√≠a haga su presentaci√≥n de este plato!

En el escenario de presentaci√≥n, Sof√≠a habla de la historia detr√°s del plato, la influencia de su cultura y la importancia del amor y la emoci√≥n en la cocina. Los cr√≠ticos se quedan impresionados por la pasi√≥n de Sof√≠a por su cocina. Hugo, con una sonrisa, levanta un vaso y toma un trago.

Me gustar√≠a decir que este plato fue el mejor que he probado en a√±os. Me encant√≥ su presentaci√≥n y la pasi√≥n de Sof√≠a. Esta cocinera tiene algo que los dem√°s no tienen. Dice Hugo, mientras Sof√≠a se convierte en la cocinera estrella del restaurante, y Hugo apoya a Sof√≠a, ahora como amigo y mentor. Sof√≠a sigue siendo ambiciosa, y con su pasi√≥n y talento, sigue creando platos que impresionan a los cr√≠ticos y a los clientes.


================================================
File: examples/fantasia.md
================================================
Aar√≥n, el carpintero, siempre sinti√≥ una melancol√≠a profunda al mirar hacia arriba. Era imposible, claro, pues el cielo de Neptuno era un oc√©ano perpetuo de nubes grises y densas, como algod√≥n. Desde ni√±o, hab√≠a escuchado historias contadas por ancianos, relatos cr√≠pticos sobre un cielo azul, radiante como el fuego, donde el sol ba√±aba la tierra en luz dorada. Legendas olvidadas, se dec√≠a, historias para dormir. Pero Aar√≥n se aferraba a ellas con la esperanza de un d√≠a poder tocar ese cielo legendario. 
Su vida transcurri√≥ entre maderas nobles y aromas dulces de la carpinter√≠a. Un d√≠a, mientras esculp√≠a una figura marina, una mujer entr√≥ en su taller. Ilara, era su nombre. Sus ojos brillaban con el color profundo del mar, y una aura parec√≠a emanar desde su interior, brillando con una luz propia. Su mirada era penetrante, y su voz, suave como la brisa marina, habl√≥ de un mundo m√°s all√° de las nubes.

"He o√≠do que buscas el cielo", dijo Ilara, con una sonrisa enigm√°tica. "S√© d√≥nde encontrarla, la llave que puede abrirlo".

La llave. Aar√≥n, cautivado por las palabras de Ilara y la promesa de un futuro diferente, decidi√≥ seguirla.

Su viaje los llev√≥ a trav√©s de cavernas submarinas h√∫medas, donde criaturas marinas luminosas danzaban en la oscuridad; a trav√©s de bosques acu√°ticos donde √°rboles gigantes parec√≠an alcanzar el cielo mismo, sus ramas cubiertas de algas que brillaban con un verde esmeralda; y hasta a las profundidades de un volc√°n submarino dormido, donde la furia del magma era palpable.

Durante el camino, Aar√≥n descubri√≥ que Ilara era mucho m√°s que una simple viajera. Era una guardi√°na, encargada de proteger las historias olvidadas de Neptuno. √âl, a cambio, aprendi√≥ sobre su propio pasado. Descubri√≥ que era descendiente de los primeros habitantes de Neptuno, aquellos que hab√≠an visto el cielo antes de que se cubriera de nubes, aquellos que hab√≠an construido Neptuno bajo la protecci√≥n de la luz solar.

Finalmente, encontraron la llave: un peque√±o cristal azul, que vibraba con una energ√≠a poderosa. Pero tambi√©n encontraron un enemigo: un antiguo mal, que hab√≠a provocado que las nubes cubrieran Neptuno, temiendo la luz del sol.

Aar√≥n, ahora armado con un conocimiento ancestral y la espada de su linaje, enfrent√≥ al mal, mientras Ilara activaba la llave. Las nubes comenzaron a dispersarse lentamente, revelando un cielo azul, brillante, maravilloso.

Pero tambi√©n descubri√≥ un secreto terrible. La llave, adem√°s de dispersar las nubes, destru√≠a la magia que proteg√≠a a Neptuno de las tormentas y las criaturas marinas monstruosas.

En ese momento, Aar√≥n tuvo que tomar una decisi√≥n: liberar al reino a la luz, arriesg√°ndose a perder la seguridad que siempre hab√≠an conocido, o mantener las nubes y proteger Neptuno en la oscuridad.

Mir√≥ hacia Ilara, cuyos ojos brillaban con l√°grimas. √âl entend√≠a su dolor, sent√≠a el peso de la elecci√≥n. Finalmente, Aar√≥n tom√≥ una decisi√≥n. Se acerc√≥ a la llave, la tom√≥ entre sus manos, y la clav√≥ en el coraz√≥n del volc√°n.

Las nubes se dispersaron, revelando un cielo azul brillante. El sol, c√°lido y dorado, ba√±aba Neptuno en luz.

Aar√≥n sab√≠a que cambiaba el destino de su reino, pero tambi√©n sab√≠a que hab√≠a elegido la verdad, la luz, y la esperanza.

Y as√≠, bajo la luz del sol, la historia de Neptuno comenz√≥ de nuevo.


================================================
File: .devcontainer/devcontainer.json
================================================
{
  "name": "Python 3",
  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile
  "image": "mcr.microsoft.com/devcontainers/python:1-3.11-bullseye",
  "customizations": {
    "codespaces": {
      "openFiles": [
        "README.md",
        "llm_storyteller_openrouter.py"
      ]
    },
    "vscode": {
      "settings": {},
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance"
      ]
    }
  },
  "updateContentCommand": "[ -f packages.txt ] && sudo apt update && sudo apt upgrade -y && sudo xargs apt install -y <packages.txt; [ -f requirements.txt ] && pip3 install --user -r requirements.txt; pip3 install --user streamlit; echo '‚úÖ Packages installed and Requirements met'",
  "postAttachCommand": {
    "server": "streamlit run llm_storyteller_openrouter.py --server.enableCORS false --server.enableXsrfProtection false"
  },
  "portsAttributes": {
    "8501": {
      "label": "Application",
      "onAutoForward": "openPreview"
    }
  },
  "forwardPorts": [
    8501
  ]
}

