import streamlit as st
import os
from agents_test import process_joblib, generate_markdown_report, group_manager, groupchat

st.title("ğŸ” Machine Learning Model Evaluator")

uploaded_file = st.file_uploader("ğŸ“‚ Carga un archivo .joblib", type=["joblib"])

if uploaded_file:
    file_path = "temp_model.joblib"
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.subheader("âš™ï¸ Procesando el modelo...")
    model_info = process_joblib(file_path)

    if "error" in model_info:
        st.error(model_info["error"])
    else:
        st.success("âœ… Modelo analizado con Ã©xito")
        # BotÃ³n para iniciar la evaluaciÃ³n con los agentes
        if st.button("ğŸ”„ Iniciar EvaluaciÃ³n con los Agentes"):
            group_manager.initiate_chat(
                recipient=group_manager,
                max_turns=3,  # Puedes ajustar este valor
                message=f"Analyze the following ML model: {model_info} and generate a Markdown report."
            )
            st.success("âœ… EvaluaciÃ³n en proceso. Espera unos segundos...")

        # BotÃ³n para finalizar la evaluaciÃ³n y descargar el reporte
        if st.button("ğŸ“„ Finalizar AnÃ¡lisis y Descargar Reporte"):
            if groupchat.messages:

                st.subheader("ğŸ“Š Resultados del Modelo")
                with st.expander("ğŸ“Œ InformaciÃ³n del Modelo"):
                    st.write(f"**Tiempo de carga:** {model_info['load_time']:.4f} segundos")
                    st.write(f"**TamaÃ±o en disco:** {model_info['size_on_disk']:.4f} MB")
                    st.write(f"**Uso de memoria:** {model_info['memory_usage']:.2f} MB")
                    st.write(f"**Rendimiento:** {model_info['throughput']:.2f} muestras/segundo")
                    st.write(f"**RecomendaciÃ³n final:** {model_info['final_recommendation']}")
                
                with st.expander("ğŸ“ˆ MÃ©tricas de Rendimiento"):
                    perf = model_info['performance_metrics']
                    st.write(f"- **Pico de memoria:** {perf['memory_peak']}")
                    st.write(f"- **Uso de CPU:** {perf['cpu_usage']}%")
                    st.write(f"- **Tiempo de predicciÃ³n:** {perf['prediction_time']:.4f} segundos")
                
                with st.expander("âš ï¸ Pruebas de Robustez"):
                    robustness = model_info['robustness_tests']
                    st.write(f"- **Valores nulos:** {robustness['null_values']}")
                    st.write(f"- **Fuera de rango:** {robustness['out_of_range']}")
                    st.write(f"- **Tipo de datos incorrecto:** {robustness['wrong_data_type']}")
                    st.write(f"- **Predicciones consistentes:** {robustness['consistent_predictions']}")

                st.subheader("ğŸ“„ Reporte Generado")
                report = generate_markdown_report(groupchat.messages)
                with open("model_analysis_report.md", "r", encoding="utf-8") as f:
                    st.download_button("â¬‡ï¸ Descargar Reporte", f, "model_analysis_report.md", "text/markdown")
            else:
                st.warning("âš ï¸ No hay mensajes en el chat de grupo. No se generÃ³ reporte.")

    os.remove(file_path)  # Limpieza del archivo temporal
